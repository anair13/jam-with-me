<p id="notice"><%= notice %></p>

<p>
  <b>Firebase identifier:</b>
  <%= @song.firebase_identifier %>
</p>


<%= link_to 'Edit', edit_song_path(@song) %> |
<%= link_to 'Back', songs_path %>

<script type="text/javascript">


var context = new AudioContext();
var firebase_song_identifier = "https://jamwithme.firebaseio.com/music/<%= @song.firebase_identifier %>";
window.onload = init;
var bufferLoader;

var buffers = new Array();
var notes = new Array();

var playbackStartTime = context.currentTime + 0.100;
var tempo = 80; // BPM (beats per minute)
var atomNoteTime = (60 / tempo) / 8; // 32nd note

var MINUTES = 20;
var d = new Date();
var startTime = d.getTime();
var thissession = new Firebase('https://jamwithme.firebaseio.com/music/thissession');
thissession.on('value', function(snapshot) {
  var session = snapshot.val();
  var ID = session.ID;
  var endTime = session.endTime;

  setInterval(function() {
    var thisDate = new Date();
    $('#box_header').text(get_elapsed_time_string(Math.floor((endTime - thisDate.getTime())/1000)));
  }, 1000);
  var temp = d.getTime()
  setTimeout(function() {
    killSession();
  },endTime - startTime);

  var myDataRef = new Firebase(firebase_song_identifier);
  $('#position').keypress(function (e) {
    var n = d.getTime();
    if(n > endTime) {
      killSession();
    }
    if (e.keyCode == 13) {
      var step = $('#step').val();
      var length = $('#length').val();
      var type = $('#type').val();
      var position = $('#position').val();
      myDataRef.push({step: step, length: length, type:type, position: position});
      $('#position').val('');
    }
  });
  myDataRef.on('child_added', function(snapshot) {
    var message = snapshot.val();
    playNote(message.step, message.length, message.type, message.position);
  });

});

function displayChatMessage(step, length) {
  $('<div/>').text(step).prepend($('<em/>').text(length+': ')).appendTo($('#messagesDiv'));
  $('#messagesDiv')[0].scrollTop = $('#messagesDiv')[0].scrollHeight;
};

function killSession() {
  var n = d.getTime();
  var endTime = n + MINUTES * 60 * 1000;
  thissession.set({ID: n, endTime: endTime});
  location.reload(true);
}

function get_elapsed_time_string(total_seconds) {
    function pretty_time_string(num) {
      return ( num < 10 ? "0" : "" ) + num;
    }

    var hours = Math.floor(total_seconds / 3600);
    total_seconds = total_seconds % 3600;

    var minutes = Math.floor(total_seconds / 60);
    total_seconds = total_seconds % 60;

    var seconds = Math.floor(total_seconds);

    // Pad the minutes and seconds with leading zeros, if required
    hours = pretty_time_string(hours);
    minutes = pretty_time_string(minutes);
    seconds = pretty_time_string(seconds);

    // Compose the string for display
    var currentTimeString = hours + ":" + minutes + ":" + seconds;

    return currentTimeString;
}

function init() {
  // Fix up prefixing
  window.AudioContext = window.AudioContext || window.webkitAudioContext;
  context = new AudioContext();

  bufferLoader = new BufferLoader(
    context,
    [
      "../assets/pianoc4.wav",
      "../assets/violinc5.wav",
//    "http://localhost:3000/assets/guitarc4.wav"
    ],
    finishedLoading
    );

  bufferLoader.load();
}

function finishedLoading(bufferList) {
  buffers = bufferList;
}

function playNote(step, length, type, position) {
    // convert type of instrument to corresponding bufferIndex
    bufferIndex = 0;
    switch (type) {
        case "piano":
            bufferIndex = 1;
        case "violin":
            bufferIndex = 2;
        default:
            bufferIndex = 0;
    }
    var timeOn = playbackStartTime + position * atomNoteTime;
    var timeOff = timeOn + length * atomNoteTime;
    var source = getTone(step, bufferIndex);
    source.start(timeOn);
    source.noteOff(timeOff);
}

// Generates a source from a buffer and shifts it to the right tone
function getTone(semitones, bufferIndex) {
  var source = context.createBufferSource();
  source.buffer = buffers[bufferIndex];
  source.connect(context.destination);
  var semitoneRatio = Math.pow(2, 1/12);
  source.playbackRate.value = Math.pow(semitoneRatio, semitones);
  if (!source.start)
    source.start = source.noteOn;
  return source;
}

// var rec = new Recorder(context.destination, {workerPath: "/assets/recorderWorker.js"});

function playback() {
  rec.record();
  playbackStartTime = context.currentTime + 0.100;
  var myDataRef = new Firebase(firebase_song_identifier);
  myDataRef.on('child_added', function(snapshot) {
    var message = snapshot.val();
    playNote(message.step, message.length, message.type, message.position);
  });
}

// function stopRecording() {
//     rec.stop();
//     createDownloadLink();
    
//     rec.clear();
//   }

// function createDownloadLink() {
//     rec && recorder.exportWAV(function(blob) {
//       var url = URL.createObjectURL(blob);
//       var li = document.createElement('li');
//       var au = document.createElement('audio');
//       var hf = document.createElement('a');
      
//       au.controls = true;
//       au.src = url;
//       hf.href = url;
//       hf.download = new Date().toISOString() + '.wav';
//       hf.innerHTML = hf.download;
//       li.appendChild(au);
//       li.appendChild(hf);
//       recordingslist.appendChild(li);
//     });
// }

</script>

<!-- <input id="clickMe" type="button" value="Play" onclick="playback();" />
<input id="clickMe" type="button" value="Stop Recording" onclick="stopRecording();" />
 -->
<div id="box_header">&nbsp;</div>
<div id='messagesDiv'></div>
<input type='text' id='step' placeholder='step'>
<input type='text' id='length' placeholder='length'>
<input type='text' id='type' placeholder='type'>
<input type='text' id='position' placeholder='position'>

<h2>Recordings</h2>
<ul id="recordingslist"></ul>